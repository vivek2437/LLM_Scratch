{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecd2570-7148-4fb1-b621-8fd383090c43",
   "metadata": {},
   "source": [
    "# 4 Pretraining on unlabeld data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6da2b6-87df-4609-9f78-f2bf7e5742c0",
   "metadata": {},
   "source": [
    "# 4.1 Evaluating genrative text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce555502-3c89-45b7-9aa3-061f65d3f2e6",
   "metadata": {},
   "source": [
    "# 4.1.1 Using GPT to genrate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa3f80de-8820-4259-809d-6f31dccf9740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.6\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.8.0+cu129\n",
      "tensorflow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "549c1eeb-d39d-4e45-ba76-5b7340589472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llm_gpt import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae981695-1a09-498c-a921-861478fb7b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from llm_gpt import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d56099-f0e3-4409-b6a0-561874c6000e",
   "metadata": {},
   "source": [
    "# 4.1.2 Calculating the textt generation loss:cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94049a11-e039-48fd-b9de-2cb7d168b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2026bf-9590-4cf9-b7b5-7860350abedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be7b12e4-251d-45f0-8cc4-9eddf321d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e399821-47a7-4b3c-ba58-c779bae85d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b709aa4b-fa3d-431c-aa97-53f65ed21ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "\n",
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ccb703e-0dfe-44ce-8c0d-f9727a8c3348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)\n",
    "\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e8d69c-ab9f-447e-ba52-7b18a18107f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n",
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)\n",
    "\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76abbf2-23fc-472e-8e3e-df38e68956f6",
   "metadata": {},
   "source": [
    "# 4.1.3 Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd39dc6f-509d-4b0a-9dd3-3edaff5201b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    response = requests.get(url, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    text_data = response.text\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec3c2f87-23a1-42f6-b124-bc4845e510ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# First 99 characters\n",
    "print(text_data[:99])\n",
    "\n",
    "# Last 99 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d452ee86-f1e9-4f02-9286-3540ef108f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09ac41d9-6417-4b93-b48f-cbfeb5552556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ' ', ',', ' ', 'world.', ' ', 'This', ' ', 'is', ' ', 'a', ' ', 'test.']\n",
      "['Hello', ',', 'world.', 'This', 'is', 'a', 'test.']\n",
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 7]\n",
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<endoftext|>', 1130)\n",
      "('|unk|>', 1131)\n",
      "5145\n",
      "x: [290, 4920, 2241, 287]\n",
      "y: [4920, 2241, 287, 257]\n",
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n",
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n",
      "[tensor([[1807, 3619,  402,  271]]), tensor([[ 3619,   402,   271, 10899]])]\n",
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n",
      "Parameter containing:\n",
      "tensor([[-0.5728,  0.2498,  1.2100,  ..., -1.0395,  0.0552,  1.3901],\n",
      "        [ 1.4865,  0.3712, -0.0122,  ..., -0.9707, -1.2034, -1.5485],\n",
      "        [-0.2655,  0.8484,  0.8453,  ...,  1.4388, -0.9206,  0.1130],\n",
      "        ...,\n",
      "        [-0.4846,  0.8505, -0.6494,  ...,  0.4114,  0.8843,  0.0172],\n",
      "        [ 0.2410,  1.8489,  0.0315,  ...,  0.1186,  1.7237,  0.0456],\n",
      "        [ 0.1451,  0.7109,  0.7407,  ...,  0.2228, -0.6726,  0.2676]],\n",
      "       requires_grad=True)\n",
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,\n",
      "           257,  7026, 15632,   438,  2016,   257,   922,  5891,  1576,   438,\n",
      "           568,   340,   373,   645,  1049,  5975,   284,   502,   284,  3285,\n",
      "           326,    11,   287,   262,  6001,   286,   465, 13476,    11,   339,\n",
      "           550,  5710,   465, 12036,    11,  6405,   257,  5527, 27075,    11],\n",
      "        [  290,  4920,  2241,   287,   257,  4489,    64,   319,   262, 34686,\n",
      "         41976,    13,   357, 10915,   314,  2138,  1807,   340,   561,   423,\n",
      "           587, 10598,   393, 28537,  2014,   198,   198,     1,   464,  6001,\n",
      "           286,   465, 13476,     1,   438,  5562,   373,   644,   262,  1466,\n",
      "          1444,   340,    13,   314,   460,  3285,  9074,    13, 46606,   536],\n",
      "        [ 5469,   438, 14363,   938,  4842,  1650,   353,   438,  2934,   489,\n",
      "          3255,   465, 48422,   540,   450,    67,  3299,    13,   366,  5189,\n",
      "          1781,   340,   338,  1016,   284,  3758,   262,  1988,   286,   616,\n",
      "          4286,   705,  1014,   510,    26,   475,   314,   836,   470,   892,\n",
      "           286,   326,    11,  1770,    13,  8759,  2763,   438,  1169,  2994],\n",
      "        [  284,   943, 17034,   318,   477,   314,   892,   286,   526,   383,\n",
      "          1573,    11,   319,  9074,    13,   536,  5469,   338, 11914,    11,\n",
      "         33096,   663,  4808,  3808,    62,   355,   996,   484,   547, 12548,\n",
      "           287,   281, 13079,   410, 12523,   286, 22353,    13,   843,   340,\n",
      "           373,   407,   691,   262,  9074,    13,   536, 48819,   508, 25722],\n",
      "        [  276,    13, 11161,   407,   262, 40123, 18113,   544,  9325,   701,\n",
      "            11,   379,   262,   938,   402,  1617,   261, 12917,   905,    11,\n",
      "          5025,   502,   878,   402,   271, 10899,   338,   366, 31640,    12,\n",
      "            67, 20811,     1,   284,   910,    11,   351, 10953,   287,   607,\n",
      "          2951,    25,   366,  1135,  2236,   407,   804,  2402,   663,   588],\n",
      "        [  757, 13984,   198,   198,  5779, 28112, 10197,   832,   262, 46475,\n",
      "           286, 18113,   544,   338, 10953,   314,  2936,  1498,   284,  1986,\n",
      "           262,  1109,   351,  1602, 11227,   414,    13, 23676,  3619,   402,\n",
      "           271, 10899,     0,   383,  1466,   550,   925,   683,   438,   270,\n",
      "           373, 15830,   326,   484,   815, 25722,   683,    13,  9754,   465],\n",
      "        [  898,  1714,  7380, 30090,   547,  2982,    11,   290,   287,   465,\n",
      "           898,  3292,  8941,   257,  4636, 28582,    13, 18612, 35394,    30,\n",
      "          8673,    13,  1002,   340,   547,    11,   262, 15393,   286,   262,\n",
      "          5977,   373, 29178,  3474,   416,  1310, 40559, 11959,  1636,    11,\n",
      "           508,    11,   287,   477,   922,  4562,    11,  3181,   503,   287],\n",
      "        [  262, 37090,   257,   845, 22665,   366,   672,   270,  2838,     1,\n",
      "           319,  3619,   438,   505,   286,   883,   905,    88,  6685, 42070,\n",
      "           351,  4738,  6276,   871,   326,   314,   423,  2982,   357,    40,\n",
      "          1839,   470,   910,   416,  4150,     8,  3688,   284,   402,   271,\n",
      "         10899,   338, 12036,    13,   843,   523,   438, 14363, 10568,   852]])\n",
      "\n",
      "Inputs Shape:\n",
      " torch.Size([8, 50])\n",
      "torch.Size([50, 256])\n",
      "torch.Size([8, 50, 256])\n"
     ]
    }
   ],
   "source": [
    "from text_data import create_dataloader_V1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.80\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_V1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_V1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0798bd7-242a-4c03-8570-887b0db02f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54a142f9-9114-4733-b8db-f4049e2d16dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77468fc6-d1d2-41a6-af28-1a3e3e567998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4096\n",
      "Validation tokens: 1024\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba411a0f-dfb0-4f01-aecb-2c4484029d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cedadd04-c4ce-4b07-a02b-e2be7e044dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "115ec3f5-a723-49e2-97e2-e64401050f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.992259979248047\n",
      "Validation loss: 10.983443260192871\n"
     ]
    }
   ],
   "source": [
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbf879b-87a2-4c66-ab58-fe4ab3d9ff56",
   "metadata": {},
   "source": [
    "# 4.2 Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70ba9ea3-cd70-4240-8128-5ba427f4d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "              )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12a0422d-efac-4462-b0f9-1f980850ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.758, Val loss 10.080\n",
      "Ep 1 (Step 000005): Train loss 8.061, Val loss 8.353\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000010): Train loss 6.663, Val loss 7.224\n",
      "Ep 2 (Step 000015): Train loss 5.912, Val loss 6.847\n",
      "Every effort moves you, the, the, the, the, the,, the, the,,, the,,, the,, the,,, the,, the,,, the, the,, the,, the,, the, the\n",
      "Ep 3 (Step 000020): Train loss 5.629, Val loss 6.774\n",
      "Every effort moves you, and, and the of the \", and, and, and, and, and, and, and, and of the of the, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000025): Train loss 5.291, Val loss 6.833\n",
      "Ep 4 (Step 000030): Train loss 4.844, Val loss 6.774\n",
      "Every effort moves you of the \" the of the of the of the a a a of the of the \" \" of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of\n",
      "Ep 5 (Step 000035): Train loss 4.309, Val loss 7.004\n",
      "Every effort moves you know one, and I had been--his, I was a dep I had been, I had been--and The women had been, I was not--and that, I had been to have to have to have to have to have, I\n",
      "Ep 6 (Step 000040): Train loss 3.842, Val loss 6.781\n",
      "Ep 6 (Step 000045): Train loss 3.172, Val loss 6.643\n",
      "Every effort moves you know one of the picture--and he was \" the fact with a laugh: \"Yes--and's an to me to have to me--it, I was _not_ interesting--and I had been, and \"There--that I was\n",
      "Ep 7 (Step 000050): Train loss 3.130, Val loss 6.621\n",
      "Ep 7 (Step 000055): Train loss 2.449, Val loss 6.625\n",
      "Every effort moves you know he was not that my hostess was his pictures--as of the picture.           \"I didn't the head to me.   \"I didn't--and that he was his\n",
      "Ep 8 (Step 000060): Train loss 2.076, Val loss 6.636\n",
      "Every effort moves you know he was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fullest reassurance.                       \n",
      "Ep 9 (Step 000065): Train loss 1.686, Val loss 6.731\n",
      "Ep 9 (Step 000070): Train loss 1.225, Val loss 6.797\n",
      "Every effort moves you know he was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fullest reassurance. It was just because she was _not_ interesting--if I may be pardoned the bull--that I found\n",
      "Ep 10 (Step 000075): Train loss 1.026, Val loss 6.850\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs. \"Oh, and I was, in fact, and Mrs. Stroud, and I had been, and he was his own sex fewer regrets were heard, and in his\n",
      "Training completed in 6.30 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe4f7076-9500-4e98-a14a-e9d1d4e31bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f5e3e7-f442-465c-86c3-4291cfa6f1bb",
   "metadata": {},
   "source": [
    "# 4.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7facef0c-6602-4b17-a582-59237e05dadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the picture for nothing--I told Mrs.\n",
      "\"Oh, and I was, in fact,\n"
     ]
    }
   ],
   "source": [
    "inference_device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(inference_device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885e654-3db5-4489-9ea9-13d72981f3d8",
   "metadata": {},
   "source": [
    "# 4.3.1 Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed376b33-e45d-4904-a14e-2ce552882009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "101a33ad-46b6-4bed-8181-9e4744eef558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1edddf9-c440-4bd9-a070-e8b829b87349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e47c984e-5670-4669-b6b3-3cd5b33befd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cc9faff-cbd4-47dc-a945-ff74661490dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1a17b-4699-4c90-9a5a-c0b68fc575c3",
   "metadata": {},
   "source": [
    "# 4.3.2 Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a784bfe8-5de0-4d9d-9b75-6e37f09a461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca21b31d-97f5-4e7f-8e0d-6cd913f37915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb1c111-d1f4-464a-81f8-5b3f97bd73d2",
   "metadata": {},
   "source": [
    "# 4.3.3 Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a38411bb-16b5-4d96-8dcc-9100c2b68089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # New (not in book): numerical stability tip to get equivalent results on mps device\n",
    "            # subtract rowwise max before softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f95c873d-0822-4ade-85f9-2cc85a86cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you not to work on surprise. It is to face the fact with random-\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f00fd8-de9e-4cec-8ce3-be0d115f2bea",
   "metadata": {},
   "source": [
    "# 4.4 Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ed6f373-e546-4ae6-941f-904fc8238316",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c71d5ab8-cd70-4487-b774-ebd87c9243c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "137b5f84-9187-4f21-a15a-c8264341b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4cdfb9c-b194-4405-a987-5e4e4de4eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90f365f-ffda-42bd-95b4-ebe442f9cd89",
   "metadata": {},
   "source": [
    "# 4.4 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6faaf647-abfc-47b0-b515-1587a727689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.41.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.32.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e03fc0c7-0738-4e34-a1ff-2fba2e11804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef732c26-02a9-4472-9d04-3845b7defcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<?, ?iB/s]\n",
      "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:02<00:00, 449kiB/s]\n",
      "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.0/90.0 [00:00<?, ?iB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498M/498M [07:10<00:00, 1.16MiB/s]\n",
      "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.21k/5.21k [00:00<?, ?iB/s]\n",
      "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471k/471k [00:01<00:00, 274kiB/s]\n",
      "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:01<00:00, 316kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n",
    "\n",
    "print(\"Settings:\", settings)\n",
    "\n",
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01f505ff-4274-4ab3-a770-a07ce269face",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7ec1b93-430b-4433-8966-86b78f4021ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c33567b-cbe5-4399-a928-d17445ef284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16c1e2e3-674f-4d42-bdeb-44a9db1a9935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
